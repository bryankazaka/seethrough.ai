{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01f3f4f3",
   "metadata": {},
   "source": [
    "This script involves finetuning the SmolVLM2 model on the real/synthetic video video classification task. First we import all our relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd0e900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in d:\\course\\computer science\\cs5983\\seethrough\\venv\\lib\\site-packages (2.0.8)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in d:\\course\\computer science\\cs5983\\seethrough\\venv\\lib\\site-packages (from albumentations) (4.12.0.88)\n",
      "Requirement already satisfied: PyYAML in d:\\course\\computer science\\cs5983\\seethrough\\venv\\lib\\site-packages (from albumentations) (6.0.2)\n",
      "Requirement already satisfied: scipy>=1.10.0 in d:\\course\\computer science\\cs5983\\seethrough\\venv\\lib\\site-packages (from albumentations) (1.15.3)\n",
      "Requirement already satisfied: numpy>=1.24.4 in d:\\course\\computer science\\cs5983\\seethrough\\venv\\lib\\site-packages (from albumentations) (2.1.2)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in d:\\course\\computer science\\cs5983\\seethrough\\venv\\lib\\site-packages (from albumentations) (2.11.7)\n",
      "Requirement already satisfied: albucore==0.0.24 in d:\\course\\computer science\\cs5983\\seethrough\\venv\\lib\\site-packages (from albumentations) (0.0.24)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in d:\\course\\computer science\\cs5983\\seethrough\\venv\\lib\\site-packages (from albucore==0.0.24->albumentations) (6.5.0)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in d:\\course\\computer science\\cs5983\\seethrough\\venv\\lib\\site-packages (from albucore==0.0.24->albumentations) (3.12.5)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\course\\computer science\\cs5983\\seethrough\\venv\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\course\\computer science\\cs5983\\seethrough\\venv\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in d:\\course\\computer science\\cs5983\\seethrough\\venv\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (4.12.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\course\\computer science\\cs5983\\seethrough\\venv\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (0.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'd:\\Course\\Computer Science\\CS5983\\seethrough\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install albumentations\n",
    "\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "import coremltools as ct\n",
    "import requests\n",
    "import zipfile\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import modelscope\n",
    "\n",
    "import argparse, os, random, tarfile, zipfile, subprocess, shutil\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "import csv, requests\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import decord"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4f5b6b",
   "metadata": {},
   "source": [
    "Then we load the Genvideo dataset (500GB) which contains over one million diverse AI generated and real videos, from state of the art generative video models with temporal artefacts crucial for video-based AI detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53871da5",
   "metadata": {},
   "outputs": [
    {
     "ename": "DatasetNotFoundError",
     "evalue": "Dataset 'cccnju/Gen-Video' doesn't exist on the Hub or cannot be accessed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDatasetNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:/GenVideo\u001b[39m\u001b[38;5;124m\"\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcccnju/Gen-Video\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:/GenVideo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Course\\Computer Science\\CS5983\\seethrough\\venv\\lib\\site-packages\\datasets\\load.py:1392\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[0;32m   1387\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(\n\u001b[0;32m   1388\u001b[0m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS\n\u001b[0;32m   1389\u001b[0m )\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[1;32m-> 1392\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m load_dataset_builder(\n\u001b[0;32m   1393\u001b[0m     path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[0;32m   1394\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m   1395\u001b[0m     data_dir\u001b[38;5;241m=\u001b[39mdata_dir,\n\u001b[0;32m   1396\u001b[0m     data_files\u001b[38;5;241m=\u001b[39mdata_files,\n\u001b[0;32m   1397\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m   1398\u001b[0m     features\u001b[38;5;241m=\u001b[39mfeatures,\n\u001b[0;32m   1399\u001b[0m     download_config\u001b[38;5;241m=\u001b[39mdownload_config,\n\u001b[0;32m   1400\u001b[0m     download_mode\u001b[38;5;241m=\u001b[39mdownload_mode,\n\u001b[0;32m   1401\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m   1402\u001b[0m     token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m   1403\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_kwargs,\n\u001b[0;32m   1405\u001b[0m )\n\u001b[0;32m   1407\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[0;32m   1408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "File \u001b[1;32md:\\Course\\Computer Science\\CS5983\\seethrough\\venv\\lib\\site-packages\\datasets\\load.py:1132\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[1;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, **config_kwargs)\u001b[0m\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1131\u001b[0m     features \u001b[38;5;241m=\u001b[39m _fix_for_backward_compatible_features(features)\n\u001b[1;32m-> 1132\u001b[0m dataset_module \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[38;5;66;03m# Get dataset builder class\u001b[39;00m\n\u001b[0;32m   1142\u001b[0m builder_kwargs \u001b[38;5;241m=\u001b[39m dataset_module\u001b[38;5;241m.\u001b[39mbuilder_kwargs\n",
      "File \u001b[1;32md:\\Course\\Computer Science\\CS5983\\seethrough\\venv\\lib\\site-packages\\datasets\\load.py:1025\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[1;34m(path, revision, download_config, download_mode, data_dir, data_files, cache_dir, **download_kwargs)\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt reach the Hugging Face Hub for dataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e1, (DataFilesNotFoundError, DatasetNotFoundError, EmptyDatasetError)):\n\u001b[1;32m-> 1025\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e1 \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e1, \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m):\n\u001b[0;32m   1027\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1028\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any data file at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_to_absolute_path(path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1029\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on the Hugging Face Hub either: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e1)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1030\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\Course\\Computer Science\\CS5983\\seethrough\\venv\\lib\\site-packages\\datasets\\load.py:980\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[1;34m(path, revision, download_config, download_mode, data_dir, data_files, cache_dir, **download_kwargs)\u001b[0m\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetNotFoundError(\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRevision \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt exist for dataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    978\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 980\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetNotFoundError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt exist on the Hub or cannot be accessed.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    981\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    982\u001b[0m     api\u001b[38;5;241m.\u001b[39mhf_hub_download(\n\u001b[0;32m    983\u001b[0m         repo_id\u001b[38;5;241m=\u001b[39mpath,\n\u001b[0;32m    984\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    987\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mdownload_config\u001b[38;5;241m.\u001b[39mproxies,\n\u001b[0;32m    988\u001b[0m     )\n",
      "\u001b[1;31mDatasetNotFoundError\u001b[0m: Dataset 'cccnju/Gen-Video' doesn't exist on the Hub or cannot be accessed."
     ]
    }
   ],
   "source": [
    "os.makedirs(\"D:/GenVideo\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736b7614",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENV_BASE = \"https://www.modelscope.cn/datasets/cccnju/Gen-Video/resolve/master/\"\n",
    "K400_TXT   = \"https://s3.amazonaws.com/kinetics/400/train/k400_train_path.txt\"\n",
    "\n",
    "GENV_FILES = {\n",
    "    # real\n",
    "    \"GenVideo-Val.zip\": 13.93,\n",
    "    # AI\n",
    "    \"OpenSora.tar.gz\"         : 31.72,\n",
    "    \"Latte.split.aa\"          : 42.95, \"Latte.split.ab\": 15.85,\n",
    "    \"Pika.split.aa\"           : 42.95, \"Pika.split.ab\" : 15.62,\n",
    "    \"DynamicCrafter.split.aa\" : 42.95, \"DynamicCrafter.split.ab\": 33.80,\n",
    "}\n",
    "\n",
    "K400_PARTS = [f\"train/part_{i:03}.tar.gz\" for i in range(4)] # first four parts only\n",
    "\n",
    "\n",
    "def _dl(url: str, dst: Path): # download a file only if it doesn't exist\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if dst.exists(): return\n",
    "    r = requests.get(url, stream=True)\n",
    "    r.raise_for_status()\n",
    "    total = int(r.headers.get(\"content-length\", 0))\n",
    "    with open(dst, \"wb\") as f, tqdm(total=total, unit=\"B\", unit_scale=True, desc=dst.name) as p:\n",
    "        for chunk in r.iter_content(chunk_size=1048576):\n",
    "            f.write(chunk); p.update(len(chunk))\n",
    "\n",
    "\n",
    "def download_subset(root: Path): # download the GenVideo subset to the given root folder\n",
    "    root.mkdir(parents=True, exist_ok=True)\n",
    "    # 1‑a) GenVideo shards \n",
    "    for fname in GENV_FILES:\n",
    "        _dl(GENV_BASE + fname, root / fname)\n",
    "\n",
    "    # 1‑b) minimal Kinetics‑400 subset\n",
    "    txt = requests.get(K400_TXT).text.splitlines()\n",
    "    for line in txt[:4]:  # first four tar files only\n",
    "        fname = Path(line).name\n",
    "        _dl(line, root / fname)\n",
    "\n",
    "def _extract(path: Path, out_dir: Path):\n",
    "    if path.suffix == \".zip\":\n",
    "        with zipfile.ZipFile(path) as z: z.extractall(out_dir)\n",
    "    elif path.suffixes[-2:] == [\".tar\", \".gz\"]:\n",
    "        with tarfile.open(path, \"r:gz\") as t: t.extractall(out_dir)\n",
    "\n",
    "def prepare_folders(root: Path):\n",
    "    fake, real = root / \"fake\", root / \"real\"\n",
    "    fake.mkdir(exist_ok=True); real.mkdir(exist_ok=True)\n",
    "\n",
    "    # combine split pieces first\n",
    "    for stem in {\"Latte\", \"Pika\", \"DynamicCrafter\"}:\n",
    "        pieces = sorted(root.glob(f\"{stem}.split.*\"))\n",
    "        if pieces:\n",
    "            tgt = root / f\"{stem}.tar.gz\"\n",
    "            if not tgt.exists():\n",
    "                with open(tgt, \"wb\") as w:\n",
    "                    for p in pieces:\n",
    "                        w.write(open(p, \"rb\").read())\n",
    "            _extract(tgt, fake / stem)\n",
    "\n",
    "    # single archives\n",
    "    _extract(root / \"OpenSora.tar.gz\", fake / \"OpenSora\")\n",
    "    _extract(root / \"GenVideo-Val.zip\", real / \"MSRVTT\")\n",
    "\n",
    "    # Kinetics tars land directly under real/Kinetics\n",
    "    k_dir = real / \"Kinetics\"\n",
    "    k_dir.mkdir(exist_ok=True)\n",
    "    for tar in root.glob(\"part_*.tar.gz\"):\n",
    "        _extract(tar, k_dir)\n",
    "\n",
    "def make_csv(root: Path, seed=42):\n",
    "    vids: List[Path] = list((root / \"real\").rglob(\"*.mp4\")) + \\\n",
    "                       list((root / \"fake\").rglob(\"*.mp4\"))\n",
    "    random.seed(seed); random.shuffle(vids)\n",
    "    splits = {\n",
    "        \"train\": vids[: int(.8*len(vids))],\n",
    "        \"val\"  : vids[int(.8*len(vids)): int(.9*len(vids))],\n",
    "        \"test\" : vids[int(.9*len(vids)):]\n",
    "    }\n",
    "    for split, paths in splits.items():\n",
    "        with open(root / f\"{split}.csv\", \"w\", newline=\"\") as f:\n",
    "            w = csv.writer(f); w.writerow([\"path\", \"label\"])\n",
    "            for p in paths:\n",
    "                w.writerow([p.as_posix(), int(\"real\" not in p.parts)])\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38722b6a",
   "metadata": {},
   "source": [
    "Transforms and loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2551178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TFM_TRAIN = A.Compose([\n",
    "    A.RandomResizedCrop(224, 224, scale=(.6,1.0)),\n",
    "    A.HorizontalFlip(p=.5),\n",
    "    A.GaussNoise(p=.3),\n",
    "    A.GaussianBlur(blur_limit=(3,5), p=.3),\n",
    "    A.Normalize(mean=(.485,.456,.406), std=(.229,.224,.225)),\n",
    "])\n",
    "\n",
    "TFM_VAL = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(mean=(.485,.456,.406), std=(.229,.224,.225)),\n",
    "])\n",
    "\n",
    "class BalancedVideoDataset(Dataset):\n",
    "    def __init__(self, csv_file: Path, train=True, n_frames=8):\n",
    "        import pandas as pd\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.train = train\n",
    "        self.n_frames = n_frames\n",
    "        self.mean = (.485,.456,.406); self.std = (.229,.224,.225)\n",
    "\n",
    "        # keep indices balanced each epoch\n",
    "        self.pos = self.df[self.df.label==1].index.tolist()\n",
    "        self.neg = self.df[self.df.label==0].index.tolist()\n",
    "        self.balance()\n",
    "\n",
    "    def balance(self):\n",
    "        k = min(len(self.pos), len(self.neg))\n",
    "        random.shuffle(self.pos); random.shuffle(self.neg)\n",
    "        self.indices = self.pos[:k] + self.neg[:k]\n",
    "        random.shuffle(self.indices)\n",
    "\n",
    "    def __len__(self): return len(self.indices)\n",
    "    def __getitem__(self, idx):\n",
    "        import cv2\n",
    "        row = self.df.loc[self.indices[idx]]\n",
    "        vr = decord.VideoReader(row.path)\n",
    "        tot = len(vr); idxs = np.linspace(0, tot-1, self.n_frames, dtype=int)\n",
    "        frames = vr.get_batch(idxs).asnumpy()  # (n, H, W, 3) uint8\n",
    "        aug = TFM_TRAIN if self.train else TFM_VAL\n",
    "        frames = np.stack([aug(image=f)[\"image\"].transpose(2,0,1) for f in frames])\n",
    "        label = torch.tensor([row.label], dtype=torch.float32)\n",
    "        return frames, label\n",
    "\n",
    "\n",
    "def make_loaders(root: Path, batch=8, workers=4):\n",
    "    train_ds = BalancedVideoDataset(root / \"train.csv\", train=True)\n",
    "    val_ds   = BalancedVideoDataset(root / \"val.csv\",   train=False)\n",
    "    train_loader = DataLoader(train_ds, batch, True,  num_workers=workers, drop_last=True)\n",
    "    val_loader   = DataLoader(val_ds,   batch, False, num_workers=workers)\n",
    "    return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc6cba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root = Path(\"D:/GenVideo\")\n",
    "print(\"→ Downloading...\")\n",
    "download_subset(root)\n",
    "print(\"→ Extracting...\")\n",
    "prepare_folders(root)\n",
    "print(\"→ Splitting...\")\n",
    "make_csv(root)\n",
    "print(\"✓  Done\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
