{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01f3f4f3",
   "metadata": {},
   "source": [
    "This script involves finetuning the SmolVLM2 model on the real/synthetic video video classification task. First we import all our relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cd0e900",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "import coremltools as ct\n",
    "import requests\n",
    "import zipfile\n",
    "import tarfile\n",
    "import shutil\n",
    "import subprocess\n",
    "import modelscope\n",
    "\n",
    "import argparse, os, random, tarfile, zipfile, subprocess, shutil\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "import csv, requests\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import decord\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4f5b6b",
   "metadata": {},
   "source": [
    "Then we load the Genvideo dataset (500GB) which contains over one million diverse AI generated and real videos, from state of the art generative video models with temporal artefacts crucial for video-based AI detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53871da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"D:/GenVideo\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736b7614",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENV_BASE = \"https://www.modelscope.cn/datasets/cccnju/Gen-Video/resolve/master/\"\n",
    "K400_TXT   = \"https://s3.amazonaws.com/kinetics/400/train/k400_train_path.txt\"\n",
    "\n",
    "GENV_FILES = {\n",
    "    # real: MSR-VTT\n",
    "    #\"GenVideo-Val.zip\": 13.93,\n",
    "    # fake: AI generators\n",
    "    #\"OpenSora.tar.gz\": 31.72,\n",
    "    #\"Latte.split.aa\": 42.95, \"Latte.split.ab\": 15.85,\n",
    "    #\"Pika.split.aa\": 42.95,  \"Pika.split.ab\": 15.62,\n",
    "    #\"DynamicCrafter.split.aa\": 42.95, \"DynamicCrafter.split.ab\": 33.80,\n",
    "    # Newly added fake sources (optional)\n",
    "    \"SEINE.tar.gz\": 9.03,\n",
    "    \"SD.split.ah\": 24.96,\n",
    "    \"I2VGEN_XL.split.aj\":13.92,\n",
    "    \"SVD.split.ac\": 9.38\n",
    "\n",
    "}\n",
    "# Youku real splits\n",
    "YOUKU_PREFIX = \"Youku_1M_10s\"\n",
    "YOUKU_COUNT = [\n",
    "    \"aa\"\n",
    "]\n",
    "\n",
    "#K400_PARTS = [f\"train/part_{i:03}.tar.gz\" for i in range(4)] # first four parts only\n",
    "\n",
    "\n",
    "def _dl(url: str, dst: Path):\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if dst.exists(): return\n",
    "    resp = requests.get(url, stream=True)\n",
    "    resp.raise_for_status()\n",
    "    total = int(resp.headers.get(\"content-length\", 0))\n",
    "    with open(dst, \"wb\") as f, tqdm(total=total, unit=\"B\", unit_scale=True, desc=dst.name) as p:\n",
    "        for chunk in resp.iter_content(chunk_size=33_554_432):  # 4MB\n",
    "            if not chunk: break\n",
    "            f.write(chunk); p.update(len(chunk))\n",
    "\n",
    "def download_subset(root: Path):\n",
    "    root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1) Full Kinetics-400 train parts\n",
    "    txt = requests.get(K400_TXT).text.splitlines()\n",
    "    for line in txt:\n",
    "        fname = Path(line).name\n",
    "        _dl(line, root/fname)\n",
    "\n",
    "    # 2) Youku-1M splits\n",
    "    for suf in YOUKU_COUNT:\n",
    "        fn = f\"{YOUKU_PREFIX}.split.{suf}\"\n",
    "        url = GENV_BASE + fn\n",
    "        _dl(url, root/fn)\n",
    "\n",
    "    # 3) AI archives\n",
    "    for fn in GENV_FILES:\n",
    "        _dl(GENV_BASE + fn, root/fn)\n",
    "\n",
    "def recombine_splits(pieces, tgt: Path, chunk_size=4_194_304):\n",
    "    with open(tgt, \"wb\") as w:\n",
    "        for p in pieces:\n",
    "            with open(p, \"rb\") as r:\n",
    "                shutil.copyfileobj(r, w, length=chunk_size)\n",
    "\n",
    "\n",
    "def _extract(arc: Path, out: Path):\n",
    "    out.mkdir(parents=True, exist_ok=True)\n",
    "    if arc.suffix == \".zip\":\n",
    "        with zipfile.ZipFile(arc) as z: z.extractall(out)\n",
    "    elif arc.suffixes[-2:] == [\".tar\",\".gz\"]:\n",
    "        with tarfile.open(arc,\"r:gz\") as t: t.extractall(out)\n",
    "\n",
    "\n",
    "def prepare_folders(root: Path):\n",
    "    fake_root = root / \"fake\"\n",
    "    real_root = root / \"real\"\n",
    "    fake_root.mkdir(exist_ok=True, parents=True)\n",
    "    real_root.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    # 1) Handle MSR-VTT bundle if present (GenVideo-Val.zip)\n",
    "    msrzip = root / \"GenVideo-Val.zip\"\n",
    "    if msrzip.exists():\n",
    "        tmp = root / \"_tmp_msr\"\n",
    "        if tmp.exists(): shutil.rmtree(tmp)\n",
    "        tmp.mkdir()\n",
    "        _extract(msrzip, tmp)\n",
    "        inner = next(tmp.iterdir())  # typically GenVideo-Val/\n",
    "        for cls, dest in [(\"Real\", real_root), (\"Fake\", fake_root)]:\n",
    "            src = inner / cls\n",
    "            if src.exists():\n",
    "                for child in src.iterdir():\n",
    "                    shutil.move(str(child), dest / child.name)\n",
    "        shutil.rmtree(tmp)\n",
    "\n",
    "    # 2) Extract full Kinetics-400 parts\n",
    "    # kin_dest = real_root / \"Kinetics\"\n",
    "    # kin_dest.mkdir(exist_ok=True)\n",
    "    # for tar in sorted(root.glob(\"part_*.tar.gz\")):\n",
    "    #    _extract(tar, kin_dest)\n",
    "\n",
    "    # 3) Extract Youku-1M   (Youku_1M_10s.split.* -> combine -> real/Youku)\n",
    "    yk_parts = sorted(root.glob(\"Youku_1M_10s.split.*\"))\n",
    "    if yk_parts:\n",
    "        yk_tar = root / \"Youku_1M_10s.tar.gz\"\n",
    "        recombine_splits(yk_parts, yk_tar)\n",
    "        _extract(yk_tar, real_root / \"Youku\")\n",
    "\n",
    "    # 4) Extract chosen fake sources\n",
    "    fake_sources = [\n",
    "        \"SEINE.tar.gz\",        # SEINE\n",
    "        \"SD.split.ah\",         # SD last split\n",
    "        \"I2VGEN_XL.split.aj\",  # partial I2VGen-XL\n",
    "        \"SVD.split.ac\",        # one split of SVD\n",
    "    ]\n",
    "\n",
    "    for fn in fake_sources:\n",
    "        path = root / fn\n",
    "        stem = fn.split('.')[0]\n",
    "\n",
    "        # recombine if it's a split\n",
    "        if \".split.\" in fn:\n",
    "            parts = sorted(root.glob(f\"{stem}.split.*\"))\n",
    "            if parts:\n",
    "                tar_target = root / f\"{stem}.tar.gz\"\n",
    "                recombine_splits(parts, tar_target)\n",
    "                path = tar_target\n",
    "        # extract into fake/<stem>/\n",
    "        if path.exists():\n",
    "            _extract(path, fake_root / stem)\n",
    "\n",
    "# ---------------------------------------\n",
    "# CSV SPLITS\n",
    "# ---------------------------------------\n",
    "def make_csv(root: Path, seed: int = 42):\n",
    "    # gather all clips\n",
    "    real_paths = list((root / \"real\").rglob(\"*.mp4\"))\n",
    "    fake_paths = list((root / \"fake\").rglob(\"*.mp4\"))\n",
    "\n",
    "    # determine balanced count\n",
    "    k = min(len(real_paths), len(fake_paths))\n",
    "    random.seed(seed)\n",
    "    real_sel = random.sample(real_paths, k)\n",
    "    fake_sel = random.sample(fake_paths, k)\n",
    "\n",
    "    all_sel = real_sel + fake_sel\n",
    "    random.shuffle(all_sel)\n",
    "\n",
    "    # split 80/10/10\n",
    "    n = len(all_sel)\n",
    "    train_end = int(0.8 * n)\n",
    "    val_end   = int(0.9 * n)\n",
    "    splits = {\n",
    "        \"train\": all_sel[:train_end],\n",
    "        \"val\"  : all_sel[train_end:val_end],\n",
    "        \"test\" : all_sel[val_end:]\n",
    "    }\n",
    "\n",
    "    # write CSVs\n",
    "    for name, items in splits.items():\n",
    "        csv_path = root / f\"{name}.csv\"\n",
    "        with open(csv_path, \"w\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"path\", \"label\"])\n",
    "            for p in items:\n",
    "                label = 0 if \"real\" in p.parts else 1\n",
    "                writer.writerow([p.as_posix(), label])\n",
    "\n",
    "    print(f\"Wrote splits: {', '.join([f'{k} ({len(v)})' for k,v in splits.items()])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38722b6a",
   "metadata": {},
   "source": [
    "Transforms and loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2551178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFM_TRAIN = A.Compose([\n",
    "    A.RandomResizedCrop(size=(224, 224), scale=(0.6, 1.0)),\n",
    "    A.HorizontalFlip(p=.5),\n",
    "    A.GaussNoise(p=.3),\n",
    "    A.GaussianBlur(blur_limit=(3, 5), p=.3),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                std=(0.229, 0.224, 0.225)),\n",
    "])\n",
    "\n",
    "TFM_VAL = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(mean=(.485,.456,.406), std=(.229,.224,.225)),\n",
    "])\n",
    "\n",
    "class BalancedVideoDataset(Dataset):\n",
    "    def __init__(self, csv_file: Path, train=True, n_frames=8):\n",
    "        import pandas as pd\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.train = train\n",
    "        self.n_frames = n_frames\n",
    "        self.mean = (.485,.456,.406); self.std = (.229,.224,.225)\n",
    "\n",
    "        # keep indices balanced each epoch\n",
    "        self.pos = self.df[self.df.label==1].index.tolist()\n",
    "        self.neg = self.df[self.df.label==0].index.tolist()\n",
    "        self.balance()\n",
    "\n",
    "    def balance(self):\n",
    "        k = min(len(self.pos), len(self.neg))\n",
    "        random.shuffle(self.pos); random.shuffle(self.neg)\n",
    "        self.indices = self.pos[:k] + self.neg[:k]\n",
    "        random.shuffle(self.indices)\n",
    "\n",
    "    def __len__(self): return len(self.indices)\n",
    "    def __getitem__(self, idx):\n",
    "        import cv2\n",
    "        row = self.df.loc[self.indices[idx]]\n",
    "        vr = decord.VideoReader(row.path)\n",
    "        tot = len(vr); idxs = np.linspace(0, tot-1, self.n_frames, dtype=int)\n",
    "        frames = vr.get_batch(idxs).asnumpy()  # (n, H, W, 3) uint8\n",
    "        aug = TFM_TRAIN if self.train else TFM_VAL\n",
    "        frames = np.stack([aug(image=f)[\"image\"].transpose(2,0,1) for f in frames])\n",
    "        label = torch.tensor([row.label], dtype=torch.float32)\n",
    "        return frames, label\n",
    "\n",
    "\n",
    "def make_loaders(root: Path, batch=8, workers=4):\n",
    "    train_ds = BalancedVideoDataset(root / \"train.csv\", train=True)\n",
    "    val_ds   = BalancedVideoDataset(root / \"val.csv\",   train=False)\n",
    "    train_loader = DataLoader(train_ds, batch, True,  num_workers=workers, drop_last=True)\n",
    "    val_loader   = DataLoader(val_ds,   batch, False, num_workers=workers)\n",
    "    return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc6cba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Downloading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Youku_1M_10s.split.aa: 100%|██████████| 42.9G/42.9G [8:14:25<00:00, 1.45MB/s]  \n",
      "Youku_1M_10s.split.ab:  48%|████▊     | 20.6G/42.9G [3:55:26<3:48:33, 1.63MB/s]"
     ]
    }
   ],
   "source": [
    "root = Path(\"D:/GenVideo\")\n",
    "print(\"→ Downloading...\")\n",
    "download_subset(root)\n",
    "print(\"→ Extracting...\")\n",
    "prepare_folders(root)\n",
    "print(\"→ Splitting...\")\n",
    "make_csv(root)\n",
    "print(\"✓  Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
